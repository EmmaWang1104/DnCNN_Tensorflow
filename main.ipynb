{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUVAF-K7BI0J"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/Colab\\ Notebooks/model.py /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ej3od_MFBVY-"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "from glob import glob\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "import time\n",
        "import os\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3CQ0_0DBrWT"
      },
      "outputs": [],
      "source": [
        "parser = argparse.ArgumentParser(description='')\n",
        "parser.add_argument('--epoch', dest='epoch', type=int, default=10, help='# of epochs')\n",
        "parser.add_argument('--batch_size', dest='batch_size', type=int, default=128, help='# images in batch')\n",
        "parser.add_argument('--lr', dest='lr', type=float, default=0.001, help='initial learning rate for adam')\n",
        "parser.add_argument('--use_gpu', dest='use_gpu', type=int, default=1, help='gpu flag, 1 for GPU and 0 for CPU')\n",
        "parser.add_argument('--phase', dest='phase', default='train', help='train or test')\n",
        "parser.add_argument('--temporal', action='store_true', default=False, help='Use temporal model')\n",
        "parser.add_argument('--checkpoint_dir', dest='ckpt_dir', default='/content/drive/MyDrive/Colab Notebooks/data_30/checkpoint', help='models are saved here')\n",
        "parser.add_argument('--test_dir', dest='test_dir', default='/content/drive/MyDrive/Colab Notebooks/data_30/denoised', help='denoised sample are saved here')\n",
        "args, _ = parser.parse_known_args()\n",
        "#print(\"epoch: \", args.epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADtA1fWFfEVE",
        "outputId": "0b1be13e-b913-42de-cef8-149790e9eb81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import os\n",
        "import cv2\n",
        "from google.colab import drive\n",
        "import tensorflow.compat.v1 as tf1\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "tf1.disable_v2_behavior()\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def dncnn(input, is_training=True, output_channels=3):\n",
        "    with tf.compat.v1.variable_scope('block1'):\n",
        "        output = tf.compat.v1.layers.conv2d(input, 64, 3, padding='same', activation=tf.nn.relu)\n",
        "    for layers in range(2, 19+1):\n",
        "        with tf.compat.v1.compat.v1.variable_scope('block%d' % layers):\n",
        "            output = tf.compat.v1.layers.conv2d(output, 64, 3, padding='same', name='conv%d' % layers, use_bias=False)\n",
        "            output = tf.compat.v1.nn.relu(tf.compat.v1.layers.batch_normalization(output, training=is_training))   \n",
        "    with tf.compat.v1.variable_scope('block20'):\n",
        "        output = tf.compat.v1.layers.conv2d(output, output_channels, 3, padding='same',use_bias=False)\n",
        "    return input - output\n",
        "\n",
        "filepaths = glob('/content/drive/MyDrive/Colab Notebooks/data/train/original/*.png') \n",
        "filepaths = sorted(filepaths)                          \n",
        "filepaths_noisy = glob('/content/drive/MyDrive/Colab Notebooks/data/train/noisy/*.png')\n",
        "filepaths_noisy = sorted(filepaths_noisy)\n",
        "ind = range(len(filepaths))\n",
        "#print(filepaths_noisy)\n",
        "\n",
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "class denoiser(object):\n",
        "    def __init__(self, sess, input_c_dim=3, batch_size=128):\n",
        "        self.sess = sess\n",
        "        self.input_c_dim = input_c_dim\n",
        "        # build model\n",
        "        self.Y_ = tf1.placeholder(tf.float32, [None, None, None, self.input_c_dim],\n",
        "                                 name='clean_image')\n",
        "        self.is_training = tf1.placeholder(tf.bool, name='is_training')\n",
        "        self.X = tf1.placeholder(tf1.float32, [None, None, None, self.input_c_dim])\n",
        "        self.Y = dncnn(self.X, is_training=self.is_training)\n",
        "        self.loss = (1.0 / batch_size) * tf.nn.l2_loss(self.Y_ - self.Y)\n",
        "        self.lr = tf.Variable(0.001, dtype=tf.float32, name='learning_rate')\n",
        "        #self.lr = tf1.Tensor(0,tf1.float32, name='learning_rate')\n",
        "        self.dataset = dataset(sess)\n",
        "        #optimizer = tf.keras.optimizers.Adam(self.lr)\n",
        "        optimizer = tf1.train.AdamOptimizer(self.lr)\n",
        "        update_ops = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.UPDATE_OPS)\n",
        "        with tf.compat.v1.control_dependencies(update_ops):\n",
        "            self.train_op = optimizer.minimize(self.loss)\n",
        "        init = tf.compat.v1.global_variables_initializer()\n",
        "        self.sess.run(init)\n",
        "        print(\"[*] Initialize model successfully...\")\n",
        "\n",
        "    def evaluate(self, iter_num, eval_files, noisy_files, summary_writer):\n",
        "        print(\"[*] Evaluating...\")\n",
        "        psnr_sum = 0\n",
        "        \n",
        "        for i in range(10):\n",
        "            clean_image = cv2.imread(eval_files[i])\n",
        "            clean_image = clean_image.astype('float32') / 255.0\n",
        "            clean_image = clean_image[np.newaxis, ...]\n",
        "            #clean_image = clean_image[None, :, :, :]\n",
        "            noisy = cv2.imread(noisy_files[i])\n",
        "            noisy = noisy.astype('float32') / 255.0\n",
        "            noisy = noisy[np.newaxis, ...]\n",
        "            \n",
        "            output_clean_image = self.sess.run(\n",
        "                [self.Y],feed_dict={self.Y_: clean_image,\n",
        "                           self.X: noisy,\n",
        "                           self.is_training: False})\n",
        "            psnr = psnr_scaled(clean_image, output_clean_image)\n",
        "            print(\"img%d PSNR: %.2f\" % (i + 1, psnr))\n",
        "            psnr_sum += psnr\n",
        "\n",
        "        avg_psnr = psnr_sum / 10\n",
        "\n",
        "        print(\"--- Test ---- Average PSNR %.2f ---\" % avg_psnr) \n",
        "\n",
        "    def train(self, eval_files, noisy_files, batch_size, ckpt_dir, epoch, lr, eval_every_epoch=1):\n",
        "\n",
        "        #numBatch = int(len(filepaths) * 2)\n",
        "        numBatch = int(len(filepaths))\n",
        "        # load pretrained model\n",
        "        load_model_status, global_step = self.load(ckpt_dir)\n",
        "        if load_model_status:\n",
        "            iter_num = global_step\n",
        "            start_epoch = global_step // numBatch\n",
        "            start_step = global_step % numBatch\n",
        "            print(\"[*] Model restore success!\")\n",
        "        else:\n",
        "            iter_num = 0\n",
        "            start_epoch = 0\n",
        "            start_step = 0\n",
        "            print(\"[*] Not find pretrained model!\")\n",
        "        # make summary\n",
        "        tf1.summary.scalar('loss', self.loss)\n",
        "        tf1.summary.scalar('lr', self.lr)\n",
        "        print('collections', tf1.get_collection(tf1.GraphKeys.SUMMARIES))\n",
        "        #writer = tf1.summary.FileWriter('./logs', self.sess.graph)\n",
        "        #merged = tf1.summary.merge_all()\n",
        "        writer = tf.compat.v1.summary.FileWriter('./logs', self.sess.graph)\n",
        "        merged = tf.compat.v1.summary.merge_all()\n",
        "        print('xx',merged)\n",
        "        clip_all_weights = tf1.get_collection(\"max_norm\")        \n",
        "\n",
        "        print(\"[*] Start training, with start epoch %d start iter %d : \" % (start_epoch, iter_num))\n",
        "        start_time = time.time()\n",
        "        self.evaluate(iter_num, eval_files, noisy_files, summary_writer=writer)  # eval_data value range is 0-255\n",
        "        for epoch in range(start_epoch, epoch):\n",
        "            batch_noisy = np.zeros((batch_size,64,64,3),dtype='float32')\n",
        "            batch_images = np.zeros((batch_size,64,64,3),dtype='float32')\n",
        "            for batch_id in range(start_step, numBatch):\n",
        "              try:\n",
        "                res = self.dataset.get_batch() # If we get an error retrieving a batch of patches we have to reinitialize the dataset\n",
        "              except KeyboardInterrupt:\n",
        "                raise\n",
        "              except:\n",
        "                self.dataset = dataset(self.sess) # Dataset re init\n",
        "                res = self.dataset.get_batch()\n",
        "              if batch_id==0:\n",
        "                batch_noisy = np.zeros((batch_size,64,64,3),dtype='float32')\n",
        "                batch_images = np.zeros((batch_size,64,64,3),dtype='float32')\n",
        "              ind1 = range(int(res.shape[0]/2))\n",
        "              ind1 = np.multiply(ind1,2)\n",
        "              for i in range(batch_size):\n",
        "                random.shuffle(ind1)\n",
        "                ind2 = random.randint(0,8-1)\n",
        "                batch_noisy[i] = res[ind1[0],ind2]\n",
        "                batch_images[i] = res[ind1[0]+1,ind2]\n",
        "                #print('x', [self.train_op, self.loss, merged])\n",
        "              _, loss, summary = self.sess.run(fetches = [self.train_op, self.loss, merged],\n",
        "                                                 feed_dict={self.Y_: batch_images, self.X: batch_noisy, self.lr: lr[epoch],\n",
        "                                                            self.is_training: True})\n",
        "              self.sess.run(clip_all_weights)          \n",
        "              \n",
        "              print(\"Epoch: [%2d] [%4d/%4d] time: %4.4f, loss: %.6f\"\n",
        "                     % (epoch + 1, batch_id + 1, numBatch, time.time() - start_time, loss))\n",
        "              iter_num += 1\n",
        "              writer.add_summary(summary, iter_num)\n",
        "              \n",
        "            if np.mod(epoch + 1, eval_every_epoch) == 0: ##Evaluate and save model\n",
        "                self.evaluate(iter_num, eval_files, noisy_files, summary_writer=writer)\n",
        "                self.save(iter_num, ckpt_dir)\n",
        "        print(\"[*] Training finished.\")\n",
        "\n",
        "    def save(self, iter_num, ckpt_dir, model_name='DnCNN-tensorflow'):\n",
        "        saver = tf1.train.Saver()\n",
        "        checkpoint_dir = ckpt_dir\n",
        "        if not os.path.exists(checkpoint_dir):\n",
        "            os.makedirs(checkpoint_dir)\n",
        "        print(\"[*] Saving model...\")\n",
        "        saver.save(self.sess,\n",
        "                   os.path.join(checkpoint_dir, model_name),\n",
        "                   global_step=iter_num)\n",
        "\n",
        "    def load(self, checkpoint_dir):\n",
        "        print(\"[*] Reading checkpoint...\")\n",
        "        saver = tf1.train.Saver()\n",
        "        ckpt = tf1.train.get_checkpoint_state(checkpoint_dir)\n",
        "        if ckpt and ckpt.model_checkpoint_path:\n",
        "            full_path = tf1.train.latest_checkpoint(checkpoint_dir)\n",
        "            global_step = int(full_path.split('/')[-1].split('-')[-1])\n",
        "            saver.restore(self.sess, full_path)\n",
        "            return True, global_step\n",
        "        else:\n",
        "            return False, 0\n",
        "\n",
        "    def test(self, eval_files, noisy_files, ckpt_dir, save_dir, temporal):\n",
        "        \"\"\"Test DnCNN\"\"\"\n",
        "        # init variables\n",
        "        tf1.global_variables_initializer().run()\n",
        "        assert len(eval_files) != 0, 'No testing data!'\n",
        "        load_model_status, global_step = self.load(ckpt_dir)\n",
        "        assert load_model_status == True, '[!] Load weights FAILED...'\n",
        "        print(\" [*] Load weights SUCCESS...\")\n",
        "        psnr_sum = 0\n",
        "            \n",
        "        for i in range(len(eval_files)):\n",
        "            clean_image = cv2.imread(eval_files[i])\n",
        "            clean_image = clean_image.astype('float32') / 255.0\n",
        "            clean_image = clean_image[np.newaxis, ...]\n",
        "            \n",
        "            noisy = cv2.imread(noisy_files[i])\n",
        "            noisy = noisy.astype('float32') / 255.0\n",
        "            noisy = noisy[np.newaxis, ...] \n",
        "          \n",
        "            output_clean_image = self.sess.run(\n",
        "                [self.Y],feed_dict={self.Y_: clean_image, self.X: noisy,\n",
        "                                    self.is_training: False})\n",
        "            \n",
        "            out1 = np.asarray(output_clean_image)\n",
        "               \n",
        "            psnr = psnr_scaled(clean_image, out1[0,0])\n",
        "            psnr1 = psnr_scaled(clean_image, noisy)\n",
        "            \n",
        "            print(\"img%d PSNR: %.2f , noisy PSNR: %.2f\" % (i + 1, psnr, psnr1))\n",
        "            psnr_sum += psnr\n",
        "\n",
        "            cv2.imwrite('/content/drive/MyDrive/Colab Notebooks/data/denoised/%04d.png'%(i),out1[0,0]*255.0)\n",
        "\n",
        "        avg_psnr = psnr_sum / len(eval_files)\n",
        "        print(\"--- Test ---- Average PSNR %.2f ---\" % avg_psnr)\n",
        "\n",
        "    \n",
        "class dataset(object):\n",
        "  def __init__(self,sess):\n",
        "    self.sess = sess\n",
        "    seed = time.time()\n",
        "    random.seed(seed)\n",
        "    idxs = list(ind)\n",
        "    random.shuffle(idxs)\n",
        "    \n",
        "    filenames = list()\n",
        "    for i in range(len(filepaths)):\n",
        "        filenames.append(filepaths_noisy[idxs[i]])\n",
        "        filenames.append(filepaths[idxs[i]])\n",
        "\n",
        "    # Parameters\n",
        "    num_patches = 8   # number of patches to extract from each image\n",
        "    patch_size = 64                 # size of the patches\n",
        "    num_parallel_calls = 1          # number of threads\n",
        "    batch_size = 32                # size of the batch\n",
        "    get_patches_fn = lambda image: get_patches(image, num_patches=num_patches, patch_size=patch_size)\n",
        "    dataset = (\n",
        "        tf.data.Dataset.from_tensor_slices(filenames)\n",
        "        .map(im_read, num_parallel_calls=num_parallel_calls)\n",
        "        .map(get_patches_fn, num_parallel_calls=num_parallel_calls)\n",
        "        .batch(batch_size)\n",
        "        .prefetch(batch_size)\n",
        "    )\n",
        "\n",
        "    iterator = tf.compat.v1.data.make_one_shot_iterator(dataset)\n",
        "    self.iter = iterator.get_next()\n",
        "  \n",
        "\n",
        "  def get_batch(self):\n",
        "        res = self.sess.run(self.iter)\n",
        "        return res\n",
        "        \n",
        "def im_read(filename):\n",
        "    \"\"\"Decode the png image from the filename and convert to [0, 1].\"\"\"\n",
        "    image_string = tf.io.read_file(filename)\n",
        "    image_decoded = tf.image.decode_png(image_string, channels=3)\n",
        "    # This will convert to float values in [0, 1]\n",
        "    image = tf.image.convert_image_dtype(image_decoded, tf.float32)\n",
        "    return image\n",
        "    \n",
        "def get_patches(image, num_patches=128, patch_size=64):\n",
        "    \"\"\"Get `num_patches` from the image\"\"\"\n",
        "    patches = []\n",
        "    for i in range(num_patches):\n",
        "      point1 = random.randint(0,116) # 116 comes from the image source size (180) - the patch dimension (64)\n",
        "      point2 = random.randint(0,116)\n",
        "      patch = tf.image.crop_to_bounding_box(image, point1, point2, patch_size, patch_size)\n",
        "      patches.append(patch)\n",
        "    patches = tf.stack(patches)\n",
        "    assert patches.get_shape().dims == [num_patches, patch_size, patch_size, 3]\n",
        "    return patches\n",
        "    \n",
        "def cal_psnr(im1, im2): # PSNR function for 0-255 values\n",
        "    mse = ((im1.astype(np.float) - im2.astype(np.float)) ** 2).mean()\n",
        "    psnr = 10 * np.log10(255 ** 2 / mse)\n",
        "    return psnr\n",
        "    \n",
        "def psnr_scaled(im1, im2): # PSNR function for 0-1 values\n",
        "    mse = ((im1 - im2) ** 2).mean()\n",
        "    mse = mse * (255 ** 2)\n",
        "    psnr = 10 * np.log10(255 **2 / mse)\n",
        "    return psnr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGNntKc9CBYT"
      },
      "outputs": [],
      "source": [
        "def denoiser_train(denoiser, lr):\n",
        "        noisy_eval_files = glob('/content/drive/MyDrive/Colab Notebooks/data/train/noisy/*.png')\n",
        "        noisy_eval_files = sorted(noisy_eval_files)\n",
        "        eval_files = glob('/content/drive/MyDrive/Colab Notebooks/data/train/original/*.png')\n",
        "        eval_files = sorted(eval_files)\n",
        "        denoiser.train(eval_files, noisy_eval_files, batch_size=args.batch_size, ckpt_dir=args.ckpt_dir, epoch=args.epoch, lr=lr)\n",
        "\n",
        "def denoiser_test(denoiser):\n",
        "\n",
        "    noisy_eval_files = glob('/content/drive/MyDrive/Colab Notebooks/data/test/noisy/*.png')\n",
        "    noisy_eval_files = sorted(noisy_eval_files)\n",
        "    eval_files = glob('/content/drive/MyDrive/Colab Notebooks/data/test/original/*.png')\n",
        "    eval_files = sorted(eval_files)\n",
        "    start = time.time()\n",
        "    denoiser.test(eval_files, noisy_eval_files, ckpt_dir=args.ckpt_dir, save_dir='/content/drive/MyDrive/Colab Notebooks/data/denoised', temporal=args.temporal)\n",
        "    end = time.time()\n",
        "    print (\"Elapsed time:\", end-start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "seogpyjwCJuX",
        "outputId": "211beb5f-2f20-4970-9fc1-22252b266518"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-28-f943951af392>:16: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
            "  output = tf.compat.v1.layers.conv2d(input, 64, 3, padding='same', activation=tf.nn.relu)\n",
            "<ipython-input-28-f943951af392>:19: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
            "  output = tf.compat.v1.layers.conv2d(output, 64, 3, padding='same', name='conv%d' % layers, use_bias=False)\n",
            "<ipython-input-28-f943951af392>:20: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
            "  output = tf.compat.v1.nn.relu(tf.compat.v1.layers.batch_normalization(output, training=is_training))\n",
            "<ipython-input-28-f943951af392>:22: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
            "  output = tf.compat.v1.layers.conv2d(output, output_channels, 3, padding='same',use_bias=False)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[*] Initialize model successfully...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0305 23:47:52.911903 140581049186112 saver.py:1410] Restoring parameters from /content/drive/MyDrive/Colab Notebooks/data_30/checkpoint/DnCNN-tensorflow-4000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[*] Reading checkpoint...\n",
            " [*] Load weights SUCCESS...\n",
            "img1 PSNR: 31.29 , noisy PSNR: 20.25\n",
            "img2 PSNR: 27.91 , noisy PSNR: 20.19\n",
            "img3 PSNR: 25.64 , noisy PSNR: 20.30\n",
            "img4 PSNR: 29.92 , noisy PSNR: 20.84\n",
            "img5 PSNR: 27.03 , noisy PSNR: 20.41\n",
            "img6 PSNR: 27.07 , noisy PSNR: 20.43\n",
            "img7 PSNR: 27.32 , noisy PSNR: 20.39\n",
            "img8 PSNR: 26.48 , noisy PSNR: 20.78\n",
            "img9 PSNR: 25.35 , noisy PSNR: 20.43\n",
            "img10 PSNR: 28.61 , noisy PSNR: 20.30\n",
            "img11 PSNR: 26.70 , noisy PSNR: 20.30\n",
            "img12 PSNR: 26.55 , noisy PSNR: 20.47\n",
            "img13 PSNR: 28.46 , noisy PSNR: 20.44\n",
            "img14 PSNR: 25.61 , noisy PSNR: 20.31\n",
            "img15 PSNR: 28.14 , noisy PSNR: 20.51\n",
            "img16 PSNR: 29.33 , noisy PSNR: 20.32\n",
            "img17 PSNR: 28.97 , noisy PSNR: 20.60\n",
            "img18 PSNR: 30.61 , noisy PSNR: 21.67\n",
            "img19 PSNR: 28.01 , noisy PSNR: 20.26\n",
            "img20 PSNR: 25.66 , noisy PSNR: 20.80\n",
            "img21 PSNR: 26.17 , noisy PSNR: 21.32\n",
            "img22 PSNR: 26.98 , noisy PSNR: 20.88\n",
            "img23 PSNR: 25.97 , noisy PSNR: 20.50\n",
            "img24 PSNR: 27.19 , noisy PSNR: 20.69\n",
            "img25 PSNR: 27.70 , noisy PSNR: 20.89\n",
            "img26 PSNR: 26.39 , noisy PSNR: 20.28\n",
            "img27 PSNR: 26.42 , noisy PSNR: 20.35\n",
            "img28 PSNR: 27.41 , noisy PSNR: 20.21\n",
            "img29 PSNR: 27.56 , noisy PSNR: 20.64\n",
            "img30 PSNR: 26.24 , noisy PSNR: 20.47\n",
            "img31 PSNR: 26.87 , noisy PSNR: 20.40\n",
            "img32 PSNR: 25.30 , noisy PSNR: 20.20\n",
            "img33 PSNR: 26.50 , noisy PSNR: 20.18\n",
            "img34 PSNR: 26.75 , noisy PSNR: 20.37\n",
            "img35 PSNR: 27.29 , noisy PSNR: 20.27\n",
            "img36 PSNR: 26.40 , noisy PSNR: 20.82\n",
            "img37 PSNR: 25.95 , noisy PSNR: 20.57\n",
            "img38 PSNR: 24.31 , noisy PSNR: 20.97\n",
            "img39 PSNR: 28.46 , noisy PSNR: 20.49\n",
            "img40 PSNR: 28.40 , noisy PSNR: 20.21\n",
            "img41 PSNR: 24.76 , noisy PSNR: 20.83\n",
            "img42 PSNR: 27.07 , noisy PSNR: 20.74\n",
            "img43 PSNR: 26.79 , noisy PSNR: 20.36\n",
            "img44 PSNR: 26.11 , noisy PSNR: 20.49\n",
            "img45 PSNR: 27.56 , noisy PSNR: 20.64\n",
            "img46 PSNR: 28.01 , noisy PSNR: 20.24\n",
            "img47 PSNR: 27.06 , noisy PSNR: 20.66\n",
            "img48 PSNR: 27.68 , noisy PSNR: 20.27\n",
            "img49 PSNR: 28.28 , noisy PSNR: 20.34\n",
            "img50 PSNR: 26.85 , noisy PSNR: 20.48\n",
            "img51 PSNR: 26.38 , noisy PSNR: 20.33\n",
            "img52 PSNR: 29.77 , noisy PSNR: 20.39\n",
            "img53 PSNR: 26.76 , noisy PSNR: 20.66\n",
            "img54 PSNR: 27.92 , noisy PSNR: 20.78\n",
            "img55 PSNR: 25.69 , noisy PSNR: 20.83\n",
            "img56 PSNR: 26.20 , noisy PSNR: 20.81\n",
            "img57 PSNR: 26.36 , noisy PSNR: 20.55\n",
            "img58 PSNR: 26.80 , noisy PSNR: 20.40\n",
            "img59 PSNR: 26.91 , noisy PSNR: 21.00\n",
            "img60 PSNR: 28.16 , noisy PSNR: 20.51\n",
            "img61 PSNR: 27.69 , noisy PSNR: 20.55\n",
            "img62 PSNR: 24.38 , noisy PSNR: 22.39\n",
            "img63 PSNR: 25.71 , noisy PSNR: 20.62\n",
            "img64 PSNR: 27.70 , noisy PSNR: 20.27\n",
            "img65 PSNR: 25.08 , noisy PSNR: 20.38\n",
            "img66 PSNR: 25.73 , noisy PSNR: 20.27\n",
            "img67 PSNR: 27.42 , noisy PSNR: 20.42\n",
            "img68 PSNR: 28.80 , noisy PSNR: 20.57\n",
            "img69 PSNR: 27.24 , noisy PSNR: 20.16\n",
            "img70 PSNR: 27.55 , noisy PSNR: 20.41\n",
            "img71 PSNR: 27.04 , noisy PSNR: 20.45\n",
            "img72 PSNR: 28.24 , noisy PSNR: 20.26\n",
            "img73 PSNR: 26.53 , noisy PSNR: 20.87\n",
            "img74 PSNR: 28.46 , noisy PSNR: 20.33\n",
            "img75 PSNR: 27.70 , noisy PSNR: 20.61\n",
            "img76 PSNR: 26.73 , noisy PSNR: 20.41\n",
            "img77 PSNR: 29.85 , noisy PSNR: 20.20\n",
            "img78 PSNR: 25.91 , noisy PSNR: 20.42\n",
            "img79 PSNR: 26.04 , noisy PSNR: 20.22\n",
            "img80 PSNR: 26.00 , noisy PSNR: 20.76\n",
            "img81 PSNR: 25.66 , noisy PSNR: 20.59\n",
            "img82 PSNR: 27.14 , noisy PSNR: 20.25\n",
            "img83 PSNR: 25.37 , noisy PSNR: 20.81\n",
            "img84 PSNR: 28.84 , noisy PSNR: 20.23\n",
            "img85 PSNR: 27.13 , noisy PSNR: 20.34\n",
            "img86 PSNR: 26.36 , noisy PSNR: 20.41\n",
            "img87 PSNR: 24.67 , noisy PSNR: 20.39\n",
            "img88 PSNR: 26.99 , noisy PSNR: 20.42\n",
            "img89 PSNR: 29.02 , noisy PSNR: 20.20\n",
            "img90 PSNR: 28.82 , noisy PSNR: 20.29\n",
            "img91 PSNR: 28.90 , noisy PSNR: 20.21\n",
            "img92 PSNR: 28.79 , noisy PSNR: 20.41\n",
            "img93 PSNR: 29.64 , noisy PSNR: 21.53\n",
            "img94 PSNR: 25.88 , noisy PSNR: 20.44\n",
            "img95 PSNR: 26.44 , noisy PSNR: 20.30\n",
            "img96 PSNR: 27.42 , noisy PSNR: 21.06\n",
            "img97 PSNR: 23.95 , noisy PSNR: 21.20\n",
            "img98 PSNR: 27.96 , noisy PSNR: 20.55\n",
            "img99 PSNR: 26.03 , noisy PSNR: 20.27\n",
            "img100 PSNR: 27.13 , noisy PSNR: 20.47\n",
            "--- Test ---- Average PSNR 27.12 ---\n",
            "Elapsed time: 4.244211196899414\n"
          ]
        },
        {
          "ename": "SystemExit",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "def main(_):\n",
        "    tf.compat.v1.reset_default_graph()\n",
        "    if not os.path.exists(args.ckpt_dir):\n",
        "        os.makedirs(args.ckpt_dir)\n",
        "    if not os.path.exists(args.test_dir):\n",
        "        os.makedirs(args.test_dir)\n",
        "\n",
        "    lr = args.lr * np.ones([args.epoch])\n",
        "    lr[30:] = lr[0] / 10.0\n",
        "    if args.use_gpu:\n",
        "        # added to control the gpu memory\n",
        "        print(\"GPU\\n\")\n",
        "        gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.9)\n",
        "        with tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options)) as sess:\n",
        "            model = denoiser(sess)\n",
        "            if args.phase == 'train':\n",
        "                denoiser_train(model, lr=lr)\n",
        "            elif args.phase == 'test':\n",
        "                denoiser_test(model)\n",
        "            else:\n",
        "                print('[!]Unknown phase')\n",
        "                exit(0)\n",
        "    else:\n",
        "        print(\"CPU\\n\")\n",
        "        with tf.compat.v1.Session() as sess:\n",
        "            model = denoiser(sess)\n",
        "            if args.phase == 'train':\n",
        "                denoiser_train(model, lr=lr)\n",
        "            elif args.phase == 'test':\n",
        "                denoiser_test(model)\n",
        "            else:\n",
        "                print('[!]Unknown phase')\n",
        "                exit(0)\n",
        "\n",
        "def test():\n",
        " #   gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.9)\n",
        "    \n",
        "    gpu_options = tf.compat.v1.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.9)\n",
        "    with tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options)) as sess:\n",
        "      model = denoiser(sess)\n",
        "      denoiser_test(model)\n",
        "\n",
        "  \n",
        "if __name__ == '__main__':\n",
        "    tf.compat.v1.app.run()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "history_visible": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.1 (v3.11.1:a7a450f84a, Dec  6 2022, 15:24:06) [Clang 13.0.0 (clang-1300.0.29.30)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
